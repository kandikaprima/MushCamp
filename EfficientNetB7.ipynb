{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MushCamp EfficientNetB7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from efficientnet.tfkeras import EfficientNetB7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = r'dataset\\dataSplit\\train'\n",
    "validationPath = r'dataset\\dataSplit\\val'\n",
    "testPath = r'dataset\\dataSplit\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2232 images belonging to 9 classes.\n",
      "Found 279 images belonging to 9 classes.\n",
      "Found 288 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=0.45,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "#Train\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                            trainPath,\n",
    "                                                    target_size=(300, 300),\n",
    "                                                    batch_size=64,\n",
    "                                                    shuffle=True,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    class_mode='categorical',\n",
    "                                            )\n",
    "\n",
    "#Validation\n",
    "validation_generator=val_datagen.flow_from_directory(\n",
    "                                            validationPath,\n",
    "                                                    target_size=(300,300),\n",
    "                                                    batch_size=64,\n",
    "                                                    shuffle=True,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    class_mode='categorical',\n",
    "                                                )\n",
    "\n",
    "#Test\n",
    "test_generator=val_datagen.flow_from_directory(\n",
    "                                            testPath,\n",
    "                                                    target_size=(300,300),\n",
    "                                                    batch_size=64,\n",
    "                                                    shuffle=True,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    class_mode='categorical',\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CallBacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss',  \n",
    "                                    factor=0.4, patience=3, \n",
    "                                    verbose=1, mode='min', \n",
    "                                    min_delta=0.0001, min_lr=0,\n",
    "                                    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Model EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "258434480/258434480 [==============================] - 41s 0us/step\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model_B7 = EfficientNetB7(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(300, 300, 3),\n",
    "    pooling='avg',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layering EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model_B7.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "last_layer = pre_trained_model_B7.get_layer('avg_pool')\n",
    "last_output = last_layer.output\n",
    "\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense (9, activation='softmax')(x)\n",
    "\n",
    "model_B7 = Model( pre_trained_model_B7.input, x) \n",
    "\n",
    "model_B7.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Model with EfficeintNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "35/35 [==============================] - 77s 2s/step - loss: 1.7109 - accuracy: 0.3849 - val_loss: 1.1633 - val_accuracy: 0.6093 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "35/35 [==============================] - 45s 1s/step - loss: 1.2898 - accuracy: 0.5435 - val_loss: 0.8311 - val_accuracy: 0.7455 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "35/35 [==============================] - 47s 1s/step - loss: 1.1015 - accuracy: 0.6129 - val_loss: 0.7037 - val_accuracy: 0.7634 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "35/35 [==============================] - 47s 1s/step - loss: 0.9582 - accuracy: 0.6640 - val_loss: 0.6803 - val_accuracy: 0.7563 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "35/35 [==============================] - 46s 1s/step - loss: 0.9489 - accuracy: 0.6788 - val_loss: 0.5992 - val_accuracy: 0.7993 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "35/35 [==============================] - 47s 1s/step - loss: 0.8578 - accuracy: 0.7056 - val_loss: 0.6106 - val_accuracy: 0.7814 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.8166 - accuracy: 0.7177 - val_loss: 0.6759 - val_accuracy: 0.7455 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "35/35 [==============================] - 56s 2s/step - loss: 0.7821 - accuracy: 0.7231 - val_loss: 0.5293 - val_accuracy: 0.8387 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "35/35 [==============================] - 53s 1s/step - loss: 0.7598 - accuracy: 0.7491 - val_loss: 0.5009 - val_accuracy: 0.8280 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "35/35 [==============================] - 49s 1s/step - loss: 0.7154 - accuracy: 0.7585 - val_loss: 0.4832 - val_accuracy: 0.8315 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.7223 - accuracy: 0.7527 - val_loss: 0.5682 - val_accuracy: 0.8029 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.6699 - accuracy: 0.7697 - val_loss: 0.4704 - val_accuracy: 0.8315 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.6478 - accuracy: 0.7742 - val_loss: 0.4397 - val_accuracy: 0.8530 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "35/35 [==============================] - 48s 1s/step - loss: 0.6083 - accuracy: 0.7926 - val_loss: 0.4273 - val_accuracy: 0.8530 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "35/35 [==============================] - 47s 1s/step - loss: 0.6118 - accuracy: 0.7849 - val_loss: 0.4081 - val_accuracy: 0.8530 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "35/35 [==============================] - 47s 1s/step - loss: 0.6123 - accuracy: 0.7944 - val_loss: 0.4174 - val_accuracy: 0.8638 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "35/35 [==============================] - 47s 1s/step - loss: 0.5951 - accuracy: 0.7957 - val_loss: 0.4182 - val_accuracy: 0.8566 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.5525 - accuracy: 0.8163\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "35/35 [==============================] - 47s 1s/step - loss: 0.5525 - accuracy: 0.8163 - val_loss: 0.4175 - val_accuracy: 0.8602 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "35/35 [==============================] - 49s 1s/step - loss: 0.5084 - accuracy: 0.8163 - val_loss: 0.4168 - val_accuracy: 0.8423 - lr: 4.0000e-04\n",
      "Epoch 20/20\n",
      "35/35 [==============================] - 47s 1s/step - loss: 0.4859 - accuracy: 0.8262 - val_loss: 0.4111 - val_accuracy: 0.8495 - lr: 4.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model_B7.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 20,\n",
    "            callbacks=[reduceLROnPlat],\n",
    "            verbose = 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eval Model using Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B7_eval = model_B7.evaluate(test_generator,verbose=0)\n",
    "B7_acc = round(B7_eval[1],2) * 100\n",
    "B7_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction Image B7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.utils as image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('Saved_Models/model_EfficientNetB7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B7_eval = model_B7.evaluate(test_generator,verbose=0)\n",
    "B7_acc = round(B7_eval[1],2) * 100\n",
    "B7_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"\"\n",
    "CLASS_NAMES = ['Agglonema', 'Alocasia', 'Gelombang Cinta', 'Janda Bolong', 'Lidah Mertua', 'Lili Paris', 'Pucuk Merah', 'Suplir']\n",
    "\n",
    "img = image.load_img(img_path, target_size=(275,275))\n",
    "imgplot = plt.imshow(img)\n",
    "x = image.img_to_array(img)\n",
    "x = x/255.0\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "classes = model.predict(images, batch_size=10,verbose=0)\n",
    "print(f'Hasil Prediksi: {CLASS_NAMES[np.argmax(classes)]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\kandi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitfolders.ratio(\"dataset\\Mushrooms\", output=\"dataset\\dataSplit\",\n",
    "    seed=1337, ratio=(.7, .2, .1), group_prefix=None, move=False) # default values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = r'dataset\\dataSplit\\train'\n",
    "validationPath = r'dataset\\dataSplit\\val'\n",
    "testPath = r'dataset\\dataSplit\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3781 images belonging to 9 classes.\n",
      "Found 1078 images belonging to 9 classes.\n",
      "Found 549 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=0.45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "#Train\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                            trainPath,\n",
    "                                                    target_size=(300, 300),\n",
    "                                                    batch_size=64,\n",
    "                                                    shuffle=True,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    class_mode='categorical',\n",
    "                                            )\n",
    "\n",
    "#Validation\n",
    "validation_generator=val_datagen.flow_from_directory(\n",
    "                                            validationPath,\n",
    "                                                    target_size=(300,300),\n",
    "                                                    batch_size=64,\n",
    "                                                    shuffle=True,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    class_mode='categorical',\n",
    "                                                )\n",
    "\n",
    "#Test\n",
    "test_generator=val_datagen.flow_from_directory(\n",
    "                                            testPath,\n",
    "                                                    target_size=(300,300),\n",
    "                                                    batch_size=64,\n",
    "                                                    shuffle=True,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    class_mode='categorical',\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class names\n",
    "class_names = os.listdir(trainPath)\n",
    "print('All category : ',class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling Dataset\n",
    "image ,label = next(iter(test_generator))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(10) :\n",
    "  plt.subplot(2,5,i+1)\n",
    "  plt.imshow(image[i])\n",
    "  plt.title(class_names[np.argmax(label[i])])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss',  \n",
    "                                    factor=0.4, patience=3, \n",
    "                                    verbose=1, mode='min', \n",
    "                                    min_delta=0.0001, min_lr=0,\n",
    "                                    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet-B7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\kandi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\kandi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from efficientnet.tfkeras import EfficientNetB7\n",
    "\n",
    "pre_trained_model = EfficientNetB7(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(300, 300, 3),\n",
    "    pooling='avg',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\kandi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('avg_pool')\n",
    "last_output = last_layer.output\n",
    "\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)              \n",
    "x = layers.Dense (9, activation='softmax')(x)           \n",
    "\n",
    "model_B7 = Model( pre_trained_model.input, x) \n",
    "\n",
    "model_B7.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60/60 [==============================] - 750s 13s/step - loss: 1.2169 - accuracy: 0.5596 - val_loss: 0.9514 - val_accuracy: 0.6612 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "60/60 [==============================] - 739s 12s/step - loss: 1.1102 - accuracy: 0.5975 - val_loss: 1.0509 - val_accuracy: 0.6029 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "60/60 [==============================] - 749s 12s/step - loss: 0.9963 - accuracy: 0.6379 - val_loss: 0.8116 - val_accuracy: 0.7086 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "60/60 [==============================] - 724s 12s/step - loss: 0.9894 - accuracy: 0.6406 - val_loss: 0.7254 - val_accuracy: 0.7614 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "60/60 [==============================] - 729s 12s/step - loss: 0.9440 - accuracy: 0.6570 - val_loss: 0.6519 - val_accuracy: 0.7796 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "60/60 [==============================] - 767s 13s/step - loss: 0.9222 - accuracy: 0.6620 - val_loss: 0.6588 - val_accuracy: 0.7559 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "60/60 [==============================] - 778s 13s/step - loss: 0.8720 - accuracy: 0.6916 - val_loss: 0.7107 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.8701 - accuracy: 0.6757 \n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "60/60 [==============================] - 780s 13s/step - loss: 0.8701 - accuracy: 0.6757 - val_loss: 0.6555 - val_accuracy: 0.7760 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "60/60 [==============================] - 778s 13s/step - loss: 0.7676 - accuracy: 0.7207 - val_loss: 0.6125 - val_accuracy: 0.7778 - lr: 4.0000e-04\n",
      "Epoch 10/20\n",
      "60/60 [==============================] - 774s 13s/step - loss: 0.7284 - accuracy: 0.7326 - val_loss: 0.6865 - val_accuracy: 0.7577 - lr: 4.0000e-04\n",
      "Epoch 11/20\n",
      "60/60 [==============================] - 773s 13s/step - loss: 0.7327 - accuracy: 0.7390 - val_loss: 0.6111 - val_accuracy: 0.7741 - lr: 4.0000e-04\n",
      "Epoch 12/20\n",
      "60/60 [==============================] - 765s 13s/step - loss: 0.7169 - accuracy: 0.7358 - val_loss: 0.6219 - val_accuracy: 0.7778 - lr: 4.0000e-04\n",
      "Epoch 13/20\n",
      "60/60 [==============================] - 749s 12s/step - loss: 0.6843 - accuracy: 0.7442 - val_loss: 0.6500 - val_accuracy: 0.7687 - lr: 4.0000e-04\n",
      "Epoch 14/20\n",
      "60/60 [==============================] - ETA: 0s - loss: 0.7137 - accuracy: 0.7419 \n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "60/60 [==============================] - 748s 12s/step - loss: 0.7137 - accuracy: 0.7419 - val_loss: 0.6120 - val_accuracy: 0.7705 - lr: 4.0000e-04\n",
      "Epoch 15/20\n",
      "60/60 [==============================] - 741s 12s/step - loss: 0.6596 - accuracy: 0.7591 - val_loss: 0.5984 - val_accuracy: 0.7741 - lr: 1.6000e-04\n",
      "Epoch 16/20\n",
      "60/60 [==============================] - 727s 12s/step - loss: 0.6520 - accuracy: 0.7625 - val_loss: 0.6344 - val_accuracy: 0.7741 - lr: 1.6000e-04\n",
      "Epoch 17/20\n",
      "60/60 [==============================] - 733s 12s/step - loss: 0.6380 - accuracy: 0.7667 - val_loss: 0.6307 - val_accuracy: 0.7687 - lr: 1.6000e-04\n",
      "Epoch 18/20\n",
      "60/60 [==============================] - 712s 12s/step - loss: 0.6358 - accuracy: 0.7691 - val_loss: 0.5599 - val_accuracy: 0.8015 - lr: 1.6000e-04\n",
      "Epoch 19/20\n",
      "60/60 [==============================] - 781s 13s/step - loss: 0.6223 - accuracy: 0.7747 - val_loss: 0.5897 - val_accuracy: 0.7814 - lr: 1.6000e-04\n",
      "Epoch 20/20\n",
      "60/60 [==============================] - 760s 13s/step - loss: 0.6295 - accuracy: 0.7707 - val_loss: 0.5905 - val_accuracy: 0.7869 - lr: 1.6000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model_B7.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 20,\n",
    "            callbacks=[reduceLROnPlat],\n",
    "            verbose = 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B7_eval = model_B7.evaluate(test_generator,verbose=0)\n",
    "B7_acc = round(B7_eval[1],2) * 100\n",
    "B7_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B7.save('saved-models/model_EfficientNetB7.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(test_generator)) :\n",
    "    x,y = test_generator.next()\n",
    "    for j in range(len(y)) :\n",
    "        y_test.append(class_names[tf.argmax(y[j])])\n",
    "        y_pred.append(class_names[np.argmax(model_B3.predict(x[j][None,...],verbose=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 13),dpi=150)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "colors = [\"#393E46\",\"#393E46\"]\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "ax.text(0,-0.3,'Confusion Matrix ',fontfamily='serif',fontsize=15,fontweight='bold')\n",
    "ax.text(0,-0.12,'EfficientB7 Model',fontfamily='serif',fontsize=12,fontweight='light')\n",
    "sns.heatmap(ax=ax, data=cm,\n",
    "            square=True, cbar_kws={\"orientation\": \"horizontal\"}, cbar=False,linewidth=1.5, annot=True,cmap=colormap, \n",
    "            annot_kws={\"fontsize\":12},fmt='')\n",
    "\n",
    "ax.set_xticklabels(class_names)\n",
    "ax.set_yticklabels(class_names)\n",
    "\n",
    "ax.set_ylabel(\"Actual Label\",fontsize=10)\n",
    "ax.set_xlabel(\"Predicted Label\",fontsize=10)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "for i in range(0,8):\n",
    "    ax.add_patch(Rectangle((i, i), 1, 1, fill=True,color='#00ADB5'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.utils as image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('Saved_Models/model_EfficientNetB7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B7_eval = model_B7.evaluate(test_generator,verbose=0)\n",
    "B7_acc = round(B7_eval[1],2) * 100\n",
    "B7_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"\"\n",
    "CLASS_NAMES = ['Agglonema', 'Alocasia', 'Gelombang Cinta', 'Janda Bolong', 'Lidah Mertua', 'Lili Paris', 'Pucuk Merah', 'Suplir']\n",
    "\n",
    "img = image.load_img(img_path, target_size=(275,275))\n",
    "imgplot = plt.imshow(img)\n",
    "x = image.img_to_array(img)\n",
    "x = x/255.0\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "classes = model.predict(images, batch_size=10,verbose=0)\n",
    "print(f'Hasil Prediksi: {CLASS_NAMES[np.argmax(classes)]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

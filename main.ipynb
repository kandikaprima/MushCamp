{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset into Train, Validation, and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitfolders.ratio(\"dataset\\Mushrooms\", output=\"dataset\\dataSplit\",\n",
    "    seed=1337, ratio=(.8, .1, .1), group_prefix=None, move=False) # default values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = r'dataset\\dataSplit\\train'\n",
    "validationPath = r'dataset\\dataSplit\\val'\n",
    "testPath = r'dataset\\dataSplit\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=0.45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "#Train\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                            trainPath,\n",
    "                                                    target_size=(300, 300),\n",
    "                                                    batch_size=64,\n",
    "                                                    shuffle=True,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    class_mode='categorical',\n",
    "                                            )\n",
    "\n",
    "#Validation\n",
    "validation_generator=val_datagen.flow_from_directory(\n",
    "                                            validationPath,\n",
    "                                                    target_size=(300,300),\n",
    "                                                    batch_size=64,\n",
    "                                                    shuffle=True,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    class_mode='categorical',\n",
    "                                                )\n",
    "\n",
    "#Test\n",
    "test_generator=val_datagen.flow_from_directory(\n",
    "                                            testPath,\n",
    "                                                    target_size=(300,300),\n",
    "                                                    batch_size=64,\n",
    "                                                    shuffle=True,\n",
    "                                                    color_mode='rgb',\n",
    "                                                    class_mode='categorical',\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class names\n",
    "class_names = os.listdir(trainPath)\n",
    "print('All category : ',class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling Dataset\n",
    "image ,label = next(iter(test_generator))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(10) :\n",
    "  plt.subplot(2,5,i+1)\n",
    "  plt.imshow(image[i])\n",
    "  plt.title(class_names[np.argmax(label[i])])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CallBacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss',  \n",
    "                                    factor=0.4, patience=3, \n",
    "                                    verbose=1, mode='min', \n",
    "                                    min_delta=0.0001, min_lr=0,\n",
    "                                    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Arsitektur EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet.tfkeras import EfficientNetB0\n",
    "from efficientnet.tfkeras import EfficientNetB1\n",
    "from efficientnet.tfkeras import EfficientNetB2\n",
    "from efficientnet.tfkeras import EfficientNetB3\n",
    "from efficientnet.tfkeras import EfficientNetB4\n",
    "from efficientnet.tfkeras import EfficientNetB5\n",
    "from efficientnet.tfkeras import EfficientNetB6\n",
    "from efficientnet.tfkeras import EfficientNetB7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B-0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Model EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model_B0 = EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(300, 300, 3),\n",
    "    pooling='avg',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layering EfficeintNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('avg_pool')\n",
    "last_output = last_layer.output\n",
    "\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)              \n",
    "x = layers.Dense (9, activation='softmax')(x)           \n",
    "\n",
    "model_B0 = Model( pre_trained_model_B0.input, x) \n",
    "\n",
    "model_B0.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Model with EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B0.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 20,\n",
    "            callbacks=[reduceLROnPlat],\n",
    "            verbose = 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Model Using Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B0_eval = model_B0.evaluate(test_generator,verbose=0)\n",
    "B0_acc = round(B0_eval[1],2) * 100\n",
    "B0_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Model EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B0.save('saved-models/model_EfficientNetB0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(test_generator)) :\n",
    "    x,y = test_generator.next()\n",
    "    for j in range(len(y)) :\n",
    "        y_test.append(class_names[tf.argmax(y[j])])\n",
    "        y_pred.append(class_names[np.argmax(model_B0.predict(x[j][None,...],verbose=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 13),dpi=150)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "colors = [\"#393E46\",\"#393E46\"]\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "ax.text(0,-0.3,'Confusion Matrix ',fontfamily='serif',fontsize=15,fontweight='bold')\n",
    "ax.text(0,-0.12,'EfficientB7 Model',fontfamily='serif',fontsize=12,fontweight='light')\n",
    "sns.heatmap(ax=ax, data=cm,\n",
    "            square=True, cbar_kws={\"orientation\": \"horizontal\"}, cbar=False,linewidth=1.5, annot=True,cmap=colormap, \n",
    "            annot_kws={\"fontsize\":12},fmt='')\n",
    "\n",
    "ax.set_xticklabels(class_names)\n",
    "ax.set_yticklabels(class_names)\n",
    "\n",
    "ax.set_ylabel(\"Actual Label\",fontsize=10)\n",
    "ax.set_xlabel(\"Predicted Label\",fontsize=10)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "for i in range(0,8):\n",
    "    ax.add_patch(Rectangle((i, i), 1, 1, fill=True,color='#00ADB5'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction Image EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.utils as image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('Saved_Models/model_EfficientNetB0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B0_eval = model_B0.evaluate(test_generator,verbose=0)\n",
    "B0_acc = round(B0_eval[1],2) * 100\n",
    "B0_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"\"\n",
    "CLASS_NAMES = ['Agglonema', 'Alocasia', 'Gelombang Cinta', 'Janda Bolong', 'Lidah Mertua', 'Lili Paris', 'Pucuk Merah', 'Suplir']\n",
    "\n",
    "img = image.load_img(img_path, target_size=(275,275))\n",
    "imgplot = plt.imshow(img)\n",
    "x = image.img_to_array(img)\n",
    "x = x/255.0\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "classes = model.predict(images, batch_size=10,verbose=0)\n",
    "print(f'Hasil Prediksi: {CLASS_NAMES[np.argmax(classes)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Model EfficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model_B1 = EfficientNetB1(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(300, 300, 3),\n",
    "    pooling='avg',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layering EfficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('avg_pool')\n",
    "last_output = last_layer.output\n",
    "\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)              \n",
    "x = layers.Dense (9, activation='softmax')(x)           \n",
    "\n",
    "model_B1 = Model( pre_trained_model_B1.input, x) \n",
    "\n",
    "model_B1.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Model with EfficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B1.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 20,\n",
    "            callbacks=[reduceLROnPlat],\n",
    "            verbose = 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Model Using Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1_eval = model_B1.evaluate(test_generator,verbose=0)\n",
    "B1_acc = round(B1_eval[1],2) * 100\n",
    "B1_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Model EfficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B1.save('saved-models/model_EfficientNetB1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(test_generator)) :\n",
    "    x,y = test_generator.next()\n",
    "    for j in range(len(y)) :\n",
    "        y_test.append(class_names[tf.argmax(y[j])])\n",
    "        y_pred.append(class_names[np.argmax(model_B1.predict(x[j][None,...],verbose=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 13),dpi=150)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "colors = [\"#393E46\",\"#393E46\"]\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "ax.text(0,-0.3,'Confusion Matrix ',fontfamily='serif',fontsize=15,fontweight='bold')\n",
    "ax.text(0,-0.12,'EfficientB7 Model',fontfamily='serif',fontsize=12,fontweight='light')\n",
    "sns.heatmap(ax=ax, data=cm,\n",
    "            square=True, cbar_kws={\"orientation\": \"horizontal\"}, cbar=False,linewidth=1.5, annot=True,cmap=colormap, \n",
    "            annot_kws={\"fontsize\":12},fmt='')\n",
    "\n",
    "ax.set_xticklabels(class_names)\n",
    "ax.set_yticklabels(class_names)\n",
    "\n",
    "ax.set_ylabel(\"Actual Label\",fontsize=10)\n",
    "ax.set_xlabel(\"Predicted Label\",fontsize=10)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "for i in range(0,8):\n",
    "    ax.add_patch(Rectangle((i, i), 1, 1, fill=True,color='#00ADB5'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction Image B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.utils as image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('Saved_Models/model_EfficientNetB1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1_eval = model_B1.evaluate(test_generator,verbose=0)\n",
    "B1_acc = round(B1_eval[1],2) * 100\n",
    "B1_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"\"\n",
    "CLASS_NAMES = ['Agglonema', 'Alocasia', 'Gelombang Cinta', 'Janda Bolong', 'Lidah Mertua', 'Lili Paris', 'Pucuk Merah', 'Suplir']\n",
    "\n",
    "img = image.load_img(img_path, target_size=(275,275))\n",
    "imgplot = plt.imshow(img)\n",
    "x = image.img_to_array(img)\n",
    "x = x/255.0\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "classes = model.predict(images, batch_size=10,verbose=0)\n",
    "print(f'Hasil Prediksi: {CLASS_NAMES[np.argmax(classes)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Model EfficientNetB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model_B2 = EfficientNetB2(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(300, 300, 3),\n",
    "    pooling='avg',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### layering EfficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('avg_pool')\n",
    "last_output = last_layer.output\n",
    "\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)              \n",
    "x = layers.Dense (9, activation='softmax')(x)           \n",
    "\n",
    "model_B2 = Model( pre_trained_model_B2.input, x) \n",
    "\n",
    "model_B2.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Model with EfficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B2.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 20,\n",
    "            callbacks=[reduceLROnPlat],\n",
    "            verbose = 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Model Using Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B2_eval = model_B2.evaluate(test_generator,verbose=0)\n",
    "B2_acc = round(B2_eval[1],2) * 100\n",
    "B2_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Model EfficientNetB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B2.save('saved-models/model_EfficientNetB2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(test_generator)) :\n",
    "    x,y = test_generator.next()\n",
    "    for j in range(len(y)) :\n",
    "        y_test.append(class_names[tf.argmax(y[j])])\n",
    "        y_pred.append(class_names[np.argmax(model_B2.predict(x[j][None,...],verbose=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 13),dpi=150)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "colors = [\"#393E46\",\"#393E46\"]\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "ax.text(0,-0.3,'Confusion Matrix ',fontfamily='serif',fontsize=15,fontweight='bold')\n",
    "ax.text(0,-0.12,'EfficientB7 Model',fontfamily='serif',fontsize=12,fontweight='light')\n",
    "sns.heatmap(ax=ax, data=cm,\n",
    "            square=True, cbar_kws={\"orientation\": \"horizontal\"}, cbar=False,linewidth=1.5, annot=True,cmap=colormap, \n",
    "            annot_kws={\"fontsize\":12},fmt='')\n",
    "\n",
    "ax.set_xticklabels(class_names)\n",
    "ax.set_yticklabels(class_names)\n",
    "\n",
    "ax.set_ylabel(\"Actual Label\",fontsize=10)\n",
    "ax.set_xlabel(\"Predicted Label\",fontsize=10)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "for i in range(0,8):\n",
    "    ax.add_patch(Rectangle((i, i), 1, 1, fill=True,color='#00ADB5'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction Image B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.utils as image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('Saved_Models/model_EfficientNetB2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B2_eval = model_B2.evaluate(test_generator,verbose=0)\n",
    "B2_acc = round(B2_eval[1],2) * 100\n",
    "B2_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"\"\n",
    "CLASS_NAMES = ['Agglonema', 'Alocasia', 'Gelombang Cinta', 'Janda Bolong', 'Lidah Mertua', 'Lili Paris', 'Pucuk Merah', 'Suplir']\n",
    "\n",
    "img = image.load_img(img_path, target_size=(275,275))\n",
    "imgplot = plt.imshow(img)\n",
    "x = image.img_to_array(img)\n",
    "x = x/255.0\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "classes = model.predict(images, batch_size=10,verbose=0)\n",
    "print(f'Hasil Prediksi: {CLASS_NAMES[np.argmax(classes)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Model EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model_B3 = EfficientNetB3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(300, 300, 3),\n",
    "    pooling='avg',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layering EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('avg_pool')\n",
    "last_output = last_layer.output\n",
    "\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)              \n",
    "x = layers.Dense (9, activation='softmax')(x)           \n",
    "\n",
    "model_B3 = Model( pre_trained_model_B3.input, x) \n",
    "\n",
    "model_B3.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Model with EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B3.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 20,\n",
    "            callbacks=[reduceLROnPlat],\n",
    "            verbose = 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Model using Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B3_eval = model_B3.evaluate(test_generator,verbose=0)\n",
    "B3_acc = round(B3_eval[1],2) * 100\n",
    "B3_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Model EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B3.save('saved-models/model_EfficientNetB3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(test_generator)) :\n",
    "    x,y = test_generator.next()\n",
    "    for j in range(len(y)) :\n",
    "        y_test.append(class_names[tf.argmax(y[j])])\n",
    "        y_pred.append(class_names[np.argmax(model_B3.predict(x[j][None,...],verbose=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 13),dpi=150)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "colors = [\"#393E46\",\"#393E46\"]\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "ax.text(0,-0.3,'Confusion Matrix ',fontfamily='serif',fontsize=15,fontweight='bold')\n",
    "ax.text(0,-0.12,'EfficientB7 Model',fontfamily='serif',fontsize=12,fontweight='light')\n",
    "sns.heatmap(ax=ax, data=cm,\n",
    "            square=True, cbar_kws={\"orientation\": \"horizontal\"}, cbar=False,linewidth=1.5, annot=True,cmap=colormap, \n",
    "            annot_kws={\"fontsize\":12},fmt='')\n",
    "\n",
    "ax.set_xticklabels(class_names)\n",
    "ax.set_yticklabels(class_names)\n",
    "\n",
    "ax.set_ylabel(\"Actual Label\",fontsize=10)\n",
    "ax.set_xlabel(\"Predicted Label\",fontsize=10)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "for i in range(0,8):\n",
    "    ax.add_patch(Rectangle((i, i), 1, 1, fill=True,color='#00ADB5'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction Image B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.utils as image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('Saved_Models/model_EfficientNetB3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B3_eval = model_B3.evaluate(test_generator,verbose=0)\n",
    "B3_acc = round(B3_eval[1],2) * 100\n",
    "B3_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"\"\n",
    "CLASS_NAMES = ['Agglonema', 'Alocasia', 'Gelombang Cinta', 'Janda Bolong', 'Lidah Mertua', 'Lili Paris', 'Pucuk Merah', 'Suplir']\n",
    "\n",
    "img = image.load_img(img_path, target_size=(275,275))\n",
    "imgplot = plt.imshow(img)\n",
    "x = image.img_to_array(img)\n",
    "x = x/255.0\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "classes = model.predict(images, batch_size=10,verbose=0)\n",
    "print(f'Hasil Prediksi: {CLASS_NAMES[np.argmax(classes)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Model EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model_B4 = EfficientNetB4(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(300, 300, 3),\n",
    "    pooling='avg',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layering EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('avg_pool')\n",
    "last_output = last_layer.output\n",
    "\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)              \n",
    "x = layers.Dense (9, activation='softmax')(x)           \n",
    "\n",
    "model_B4 = Model( pre_trained_model_B4.input, x) \n",
    "\n",
    "model_B4.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Model with EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B4.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 20,\n",
    "            callbacks=[reduceLROnPlat],\n",
    "            verbose = 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Model using Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B4_eval = model_B4.evaluate(test_generator,verbose=0)\n",
    "B4_acc = round(B4_eval[1],2) * 100\n",
    "B4_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Model EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B4.save('saved-models/model_EfficientNetB4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix B4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(test_generator)) :\n",
    "    x,y = test_generator.next()\n",
    "    for j in range(len(y)) :\n",
    "        y_test.append(class_names[tf.argmax(y[j])])\n",
    "        y_pred.append(class_names[np.argmax(model_B4.predict(x[j][None,...],verbose=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 13),dpi=150)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "colors = [\"#393E46\",\"#393E46\"]\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "ax.text(0,-0.3,'Confusion Matrix ',fontfamily='serif',fontsize=15,fontweight='bold')\n",
    "ax.text(0,-0.12,'EfficientB7 Model',fontfamily='serif',fontsize=12,fontweight='light')\n",
    "sns.heatmap(ax=ax, data=cm,\n",
    "            square=True, cbar_kws={\"orientation\": \"horizontal\"}, cbar=False,linewidth=1.5, annot=True,cmap=colormap, \n",
    "            annot_kws={\"fontsize\":12},fmt='')\n",
    "\n",
    "ax.set_xticklabels(class_names)\n",
    "ax.set_yticklabels(class_names)\n",
    "\n",
    "ax.set_ylabel(\"Actual Label\",fontsize=10)\n",
    "ax.set_xlabel(\"Predicted Label\",fontsize=10)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "for i in range(0,8):\n",
    "    ax.add_patch(Rectangle((i, i), 1, 1, fill=True,color='#00ADB5'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction Image B4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.utils as image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('Saved_Models/model_EfficientNetB4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B4_eval = model_B4.evaluate(test_generator,verbose=0)\n",
    "B4_acc = round(B4_eval[1],2) * 100\n",
    "B4_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"\"\n",
    "CLASS_NAMES = ['Agglonema', 'Alocasia', 'Gelombang Cinta', 'Janda Bolong', 'Lidah Mertua', 'Lili Paris', 'Pucuk Merah', 'Suplir']\n",
    "\n",
    "img = image.load_img(img_path, target_size=(275,275))\n",
    "imgplot = plt.imshow(img)\n",
    "x = image.img_to_array(img)\n",
    "x = x/255.0\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "classes = model.predict(images, batch_size=10,verbose=0)\n",
    "print(f'Hasil Prediksi: {CLASS_NAMES[np.argmax(classes)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Model EfficientNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model_B5 = EfficientNetB5(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(300, 300, 3),\n",
    "    pooling='avg',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### layering EfficientNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('avg_pool')\n",
    "last_output = last_layer.output\n",
    "\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)              \n",
    "x = layers.Dense (9, activation='softmax')(x)           \n",
    "\n",
    "model_B5 = Model( pre_trained_model_B5.input, x) \n",
    "\n",
    "model_B5.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Model with EfficientNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B5.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 20,\n",
    "            callbacks=[reduceLROnPlat],\n",
    "            verbose = 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Model using Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B5_eval = model_B5.evaluate(test_generator,verbose=0)\n",
    "B5_acc = round(B5_eval[1],2) * 100\n",
    "B5_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Model EfficientNetB5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B5.save('saved-models/model_EfficientNetB5.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix B5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(test_generator)) :\n",
    "    x,y = test_generator.next()\n",
    "    for j in range(len(y)) :\n",
    "        y_test.append(class_names[tf.argmax(y[j])])\n",
    "        y_pred.append(class_names[np.argmax(model_B5.predict(x[j][None,...],verbose=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 13),dpi=150)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "colors = [\"#393E46\",\"#393E46\"]\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "ax.text(0,-0.3,'Confusion Matrix ',fontfamily='serif',fontsize=15,fontweight='bold')\n",
    "ax.text(0,-0.12,'EfficientB7 Model',fontfamily='serif',fontsize=12,fontweight='light')\n",
    "sns.heatmap(ax=ax, data=cm,\n",
    "            square=True, cbar_kws={\"orientation\": \"horizontal\"}, cbar=False,linewidth=1.5, annot=True,cmap=colormap, \n",
    "            annot_kws={\"fontsize\":12},fmt='')\n",
    "\n",
    "ax.set_xticklabels(class_names)\n",
    "ax.set_yticklabels(class_names)\n",
    "\n",
    "ax.set_ylabel(\"Actual Label\",fontsize=10)\n",
    "ax.set_xlabel(\"Predicted Label\",fontsize=10)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "for i in range(0,8):\n",
    "    ax.add_patch(Rectangle((i, i), 1, 1, fill=True,color='#00ADB5'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction Image B5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.utils as image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('Saved_Models/model_EfficientNetB5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B5_eval = model_B5.evaluate(test_generator,verbose=0)\n",
    "B5_acc = round(B5_eval[1],2) * 100\n",
    "B5_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"\"\n",
    "CLASS_NAMES = ['Agglonema', 'Alocasia', 'Gelombang Cinta', 'Janda Bolong', 'Lidah Mertua', 'Lili Paris', 'Pucuk Merah', 'Suplir']\n",
    "\n",
    "img = image.load_img(img_path, target_size=(275,275))\n",
    "imgplot = plt.imshow(img)\n",
    "x = image.img_to_array(img)\n",
    "x = x/255.0\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "classes = model.predict(images, batch_size=10,verbose=0)\n",
    "print(f'Hasil Prediksi: {CLASS_NAMES[np.argmax(classes)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Model EfficientNetB6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model_B6 = EfficientNetB6(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(300, 300, 3),\n",
    "    pooling='avg',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layering EfficientNetB6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('avg_pool')\n",
    "last_output = last_layer.output\n",
    "\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)              \n",
    "x = layers.Dense (9, activation='softmax')(x)           \n",
    "\n",
    "model_B6 = Model( pre_trained_model_B6.input, x) \n",
    "\n",
    "model_B6.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Model with EfficientNetB6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B6.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 20,\n",
    "            callbacks=[reduceLROnPlat],\n",
    "            verbose = 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Model using Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B6_eval = model_B6.evaluate(test_generator,verbose=0)\n",
    "B6_acc = round(B6_eval[1],2) * 100\n",
    "B6_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Model using Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B6.save('saved-models/model_EfficientNetB6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix B6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(test_generator)) :\n",
    "    x,y = test_generator.next()\n",
    "    for j in range(len(y)) :\n",
    "        y_test.append(class_names[tf.argmax(y[j])])\n",
    "        y_pred.append(class_names[np.argmax(model_B6.predict(x[j][None,...],verbose=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 13),dpi=150)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "colors = [\"#393E46\",\"#393E46\"]\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "ax.text(0,-0.3,'Confusion Matrix ',fontfamily='serif',fontsize=15,fontweight='bold')\n",
    "ax.text(0,-0.12,'EfficientB7 Model',fontfamily='serif',fontsize=12,fontweight='light')\n",
    "sns.heatmap(ax=ax, data=cm,\n",
    "            square=True, cbar_kws={\"orientation\": \"horizontal\"}, cbar=False,linewidth=1.5, annot=True,cmap=colormap, \n",
    "            annot_kws={\"fontsize\":12},fmt='')\n",
    "\n",
    "ax.set_xticklabels(class_names)\n",
    "ax.set_yticklabels(class_names)\n",
    "\n",
    "ax.set_ylabel(\"Actual Label\",fontsize=10)\n",
    "ax.set_xlabel(\"Predicted Label\",fontsize=10)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "for i in range(0,8):\n",
    "    ax.add_patch(Rectangle((i, i), 1, 1, fill=True,color='#00ADB5'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction Image B6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.utils as image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('Saved_Models/model_EfficientNetB6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B6_eval = model_B6.evaluate(test_generator,verbose=0)\n",
    "B6_acc = round(B6_eval[1],2) * 100\n",
    "B6_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"\"\n",
    "CLASS_NAMES = ['Agglonema', 'Alocasia', 'Gelombang Cinta', 'Janda Bolong', 'Lidah Mertua', 'Lili Paris', 'Pucuk Merah', 'Suplir']\n",
    "\n",
    "img = image.load_img(img_path, target_size=(275,275))\n",
    "imgplot = plt.imshow(img)\n",
    "x = image.img_to_array(img)\n",
    "x = x/255.0\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "classes = model.predict(images, batch_size=10,verbose=0)\n",
    "print(f'Hasil Prediksi: {CLASS_NAMES[np.argmax(classes)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet B-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Model EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model_B7 = EfficientNetB7(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(300, 300, 3),\n",
    "    pooling='avg',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Layering EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "last_layer = pre_trained_model.get_layer('avg_pool')\n",
    "last_output = last_layer.output\n",
    "\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)              \n",
    "x = layers.Dense (9, activation='softmax')(x)           \n",
    "\n",
    "model_B7 = Model( pre_trained_model_B7.input, x) \n",
    "\n",
    "model_B7.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Model with EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B7.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 20,\n",
    "            callbacks=[reduceLROnPlat],\n",
    "            verbose = 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Model using Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B7_eval = model_B7.evaluate(test_generator,verbose=0)\n",
    "B7_acc = round(B7_eval[1],2) * 100\n",
    "B7_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Model using Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B7.save('saved-models/model_EfficientNetB7.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion Matrix B7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(test_generator)) :\n",
    "    x,y = test_generator.next()\n",
    "    for j in range(len(y)) :\n",
    "        y_test.append(class_names[tf.argmax(y[j])])\n",
    "        y_pred.append(class_names[np.argmax(model_B7.predict(x[j][None,...],verbose=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 13),dpi=150)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "colors = [\"#393E46\",\"#393E46\"]\n",
    "colormap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "ax.text(0,-0.3,'Confusion Matrix ',fontfamily='serif',fontsize=15,fontweight='bold')\n",
    "ax.text(0,-0.12,'EfficientB7 Model',fontfamily='serif',fontsize=12,fontweight='light')\n",
    "sns.heatmap(ax=ax, data=cm,\n",
    "            square=True, cbar_kws={\"orientation\": \"horizontal\"}, cbar=False,linewidth=1.5, annot=True,cmap=colormap, \n",
    "            annot_kws={\"fontsize\":12},fmt='')\n",
    "\n",
    "ax.set_xticklabels(class_names)\n",
    "ax.set_yticklabels(class_names)\n",
    "\n",
    "ax.set_ylabel(\"Actual Label\",fontsize=10)\n",
    "ax.set_xlabel(\"Predicted Label\",fontsize=10)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "for i in range(0,8):\n",
    "    ax.add_patch(Rectangle((i, i), 1, 1, fill=True,color='#00ADB5'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction Image B7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.utils as image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('Saved_Models/model_EfficientNetB7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B7_eval = model_B7.evaluate(test_generator,verbose=0)\n",
    "B7_acc = round(B7_eval[1],2) * 100\n",
    "B7_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"\"\n",
    "CLASS_NAMES = ['Agglonema', 'Alocasia', 'Gelombang Cinta', 'Janda Bolong', 'Lidah Mertua', 'Lili Paris', 'Pucuk Merah', 'Suplir']\n",
    "\n",
    "img = image.load_img(img_path, target_size=(275,275))\n",
    "imgplot = plt.imshow(img)\n",
    "x = image.img_to_array(img)\n",
    "x = x/255.0\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "classes = model.predict(images, batch_size=10,verbose=0)\n",
    "print(f'Hasil Prediksi: {CLASS_NAMES[np.argmax(classes)]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
